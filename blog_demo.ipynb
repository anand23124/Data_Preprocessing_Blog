{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 5856 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Optional: Try importing Prophet, but handle case where it's not installed\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    prophet_available = True\n",
    "except ImportError:\n",
    "    print(\"Prophet not installed. To install: pip install prophet\")\n",
    "    prophet_available = False\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"march_april_dataset.csv\")\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "print(f\"Dataset loaded with {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:21:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:21:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet imputation completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------\n",
    "# Approach 1: Prophet-Based Imputation with Mean Adjustment\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "def prophet_imputation(df):\n",
    "    if not prophet_available:\n",
    "        print(\"Prophet not available. Install with: pip install prophet\")\n",
    "        return None\n",
    "    \n",
    "    # Create a copy to avoid modifying original data\n",
    "    df_prophet = df.copy()\n",
    "    \n",
    "    # Identify missing values\n",
    "    missing_mask = df_prophet['Reading'].isna()\n",
    "    missing_count = missing_mask.sum()\n",
    "    \n",
    "    if missing_count == 0:\n",
    "        print(\"No missing values found!\")\n",
    "        return df_prophet\n",
    "    \n",
    "    # Find indices around missing values\n",
    "    first_missing_idx = df_prophet[missing_mask].index[0]\n",
    "    last_known_idx = df_prophet.loc[:first_missing_idx][~df_prophet.loc[:first_missing_idx]['Reading'].isna()].index[-1]\n",
    "    next_known_idx = df_prophet.loc[first_missing_idx:][~df_prophet.loc[first_missing_idx:]['Reading'].isna()].index[0]\n",
    "    \n",
    "    # Calculate the expected total\n",
    "    last_known_value = df_prophet.loc[last_known_idx, 'Reading']\n",
    "    next_known_value = df_prophet.loc[next_known_idx, 'Reading']\n",
    "    expected_total = next_known_value - last_known_value\n",
    "    \n",
    "    # Set up Prophet\n",
    "    df_prophet_input = df_prophet.rename(columns={\"Timestamp\": \"ds\", \"Reading\": \"y\"})\n",
    "    model = Prophet(daily_seasonality=True)\n",
    "    model.fit(df_prophet_input.dropna())\n",
    "    \n",
    "    # Create future dataframe and predict\n",
    "    future = df_prophet_input.copy()\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # Use predictions for missing values\n",
    "    df_prophet_result = df_prophet.copy()\n",
    "    df_prophet_result['prophet_values'] = forecast['yhat'].values\n",
    "    df_prophet_result['imputed_reading'] = df_prophet_result['Reading'].fillna(df_prophet_result['prophet_values'])\n",
    "    \n",
    "    # Scale imputed values to match the expected total\n",
    "    missing_indices = df_prophet_result.loc[last_known_idx+1:next_known_idx-1].index\n",
    "    imputed_sum = df_prophet_result.loc[missing_indices, 'imputed_reading'].sum()\n",
    "    \n",
    "    if imputed_sum > 0:  # Avoid division by zero\n",
    "        scale_factor = expected_total / imputed_sum\n",
    "        df_prophet_result.loc[missing_indices, 'imputed_reading'] = df_prophet_result.loc[missing_indices, 'imputed_reading'] * scale_factor\n",
    "    \n",
    "    # Return the final result\n",
    "    return df_prophet_result[['Timestamp', 'imputed_reading']].rename(columns={'imputed_reading': 'Reading'})\n",
    "\n",
    "# Apply Prophet imputation\n",
    "df_prophet = prophet_imputation(df) if prophet_available else None\n",
    "if df_prophet is not None:\n",
    "    print(\"Prophet imputation completed\")\n",
    "    df_prophet.to_csv(\"prophet_imputed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean imputation completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------\n",
    "# Approach 2: Mean-Based Imputation\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "def mean_imputation(df):\n",
    "    # Create a copy to avoid modifying original data\n",
    "    df_mean = df.copy()\n",
    "    \n",
    "    # Identify missing values\n",
    "    missing_mask = df_mean['Reading'].isna()\n",
    "    missing_count = missing_mask.sum()\n",
    "    \n",
    "    if missing_count == 0:\n",
    "        print(\"No missing values found!\")\n",
    "        return df_mean\n",
    "    \n",
    "    # Calculate mean of non-missing values\n",
    "    mean_value = df_mean['Reading'].dropna().mean()\n",
    "    \n",
    "    # Fill missing values with mean\n",
    "    df_mean.loc[missing_mask, 'Reading'] = mean_value\n",
    "    \n",
    "    return df_mean\n",
    "\n",
    "# Apply Mean imputation\n",
    "df_mean = mean_imputation(df)\n",
    "print(\"Mean imputation completed\")\n",
    "df_mean.to_csv(\"mean_imputed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQR imputation completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------\n",
    "# Approach 3: IQR-Based Outlier Handling and Imputation\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "def iqr_imputation(df):\n",
    "    # Create a copy to avoid modifying original data\n",
    "    df_iqr = df.copy()\n",
    "    \n",
    "    # Identify missing values\n",
    "    missing_mask = df_iqr['Reading'].isna()\n",
    "    missing_count = missing_mask.sum()\n",
    "    \n",
    "    if missing_count == 0:\n",
    "        print(\"No missing values found!\")\n",
    "        return df_iqr\n",
    "    \n",
    "    # Find indices around missing values\n",
    "    first_missing_idx = df_iqr[missing_mask].index[0]\n",
    "    last_known_idx = df_iqr.loc[:first_missing_idx][~df_iqr.loc[:first_missing_idx]['Reading'].isna()].index[-1]\n",
    "    next_known_idx = df_iqr.loc[first_missing_idx:][~df_iqr.loc[first_missing_idx:]['Reading'].isna()].index[0]\n",
    "    \n",
    "    # Calculate the expected total\n",
    "    last_known_value = df_iqr.loc[last_known_idx, 'Reading']\n",
    "    next_known_value = df_iqr.loc[next_known_idx, 'Reading']\n",
    "    expected_total = next_known_value - last_known_value\n",
    "    \n",
    "    # Step 1: Initial fill with linear interpolation\n",
    "    df_iqr['Reading'] = df_iqr['Reading'].interpolate(method='linear')\n",
    "    \n",
    "    # Step 2: Apply IQR to detect outliers\n",
    "    Q1 = df_iqr['Reading'].quantile(0.25)\n",
    "    Q3 = df_iqr['Reading'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Step 3: Replace outliers with median\n",
    "    median_value = df_iqr['Reading'].median()\n",
    "    outlier_mask = (df_iqr['Reading'] < lower_bound) | (df_iqr['Reading'] > upper_bound)\n",
    "    df_iqr.loc[outlier_mask, 'Reading'] = median_value\n",
    "    \n",
    "    # Step 4: Scale to match expected total\n",
    "    missing_indices = df_iqr.loc[last_known_idx+1:next_known_idx-1].index\n",
    "    imputed_sum = df_iqr.loc[missing_indices, 'Reading'].sum()\n",
    "    \n",
    "    if imputed_sum > 0:  # Avoid division by zero\n",
    "        scale_factor = expected_total / imputed_sum\n",
    "        df_iqr.loc[missing_indices, 'Reading'] = df_iqr.loc[missing_indices, 'Reading'] * scale_factor\n",
    "    \n",
    "    return df_iqr\n",
    "\n",
    "# Apply IQR imputation\n",
    "df_iqr = iqr_imputation(df)\n",
    "print(\"IQR imputation completed\")\n",
    "df_iqr.to_csv(\"iqr_imputed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN imputation completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------\n",
    "# Approach 4: K-Nearest Neighbors (KNN) Imputation\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "def knn_imputation(df):\n",
    "    # Create a copy to avoid modifying original data\n",
    "    df_knn = df.copy()\n",
    "    \n",
    "    # Identify missing values\n",
    "    missing_mask = df_knn['Reading'].isna()\n",
    "    missing_count = missing_mask.sum()\n",
    "    \n",
    "    if missing_count == 0:\n",
    "        print(\"No missing values found!\")\n",
    "        return df_knn\n",
    "    \n",
    "    # Find indices around missing values\n",
    "    first_missing_idx = df_knn[missing_mask].index[0]\n",
    "    last_known_idx = df_knn.loc[:first_missing_idx][~df_knn.loc[:first_missing_idx]['Reading'].isna()].index[-1]\n",
    "    next_known_idx = df_knn.loc[first_missing_idx:][~df_knn.loc[first_missing_idx:]['Reading'].isna()].index[0]\n",
    "    \n",
    "    # Calculate the expected total\n",
    "    last_known_value = df_knn.loc[last_known_idx, 'Reading']\n",
    "    next_known_value = df_knn.loc[next_known_idx, 'Reading']\n",
    "    expected_total = next_known_value - last_known_value\n",
    "    \n",
    "    # Convert timestamps to numeric for KNN\n",
    "    df_knn['Timestamp_Num'] = df_knn['Timestamp'].astype(np.int64) // 10**9\n",
    "    \n",
    "    # Apply KNN imputation\n",
    "    imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "    data_array = df_knn[['Timestamp_Num', 'Reading']].values\n",
    "    imputed_array = imputer.fit_transform(data_array)\n",
    "    \n",
    "    # Update with imputed values\n",
    "    df_knn['Reading'] = imputed_array[:, 1]\n",
    "    \n",
    "    # Scale to match expected total\n",
    "    missing_indices = df_knn.loc[last_known_idx+1:next_known_idx-1].index\n",
    "    imputed_sum = df_knn.loc[missing_indices, 'Reading'].sum()\n",
    "    \n",
    "    if imputed_sum > 0:  # Avoid division by zero\n",
    "        scale_factor = expected_total / imputed_sum\n",
    "        df_knn.loc[missing_indices, 'Reading'] = df_knn.loc[missing_indices, 'Reading'] * scale_factor\n",
    "    \n",
    "    # Clean up and return\n",
    "    df_knn = df_knn[['Timestamp', 'Reading']]\n",
    "    return df_knn\n",
    "\n",
    "# Apply KNN imputation\n",
    "df_knn = knn_imputation(df)\n",
    "print(\"KNN imputation completed\")\n",
    "df_knn.to_csv(\"knn_imputed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
